{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18edd63f",
   "metadata": {},
   "source": [
    "# 首先导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa63036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SurvivalDataset(Dataset):\n",
    "    ''' The dataset class performs loading data from .h5 file. '''\n",
    "    def __init__(self, h5_file, is_train):\n",
    "        ''' Loading data from .h5 file based on (h5_file, is_train).\n",
    "\n",
    "        :param h5_file: (String) the path of .h5 file\n",
    "        :param is_train: (bool) which kind of data to be loaded?\n",
    "                is_train=True: loading train data\n",
    "                is_train=False: loading test data\n",
    "        '''\n",
    "        # loads data\n",
    "        self.X, self.e, self.y = \\\n",
    "            self._read_h5_file(h5_file, is_train)\n",
    "        # normalizes data\n",
    "        self._normalize()\n",
    "\n",
    "        print('=> load {} samples'.format(self.X.shape[0]))\n",
    "\n",
    "    def _read_h5_file(self, h5_file, is_train):\n",
    "        ''' The function to parsing data from .h5 file.\n",
    "\n",
    "        :return X: (np.array) (n, m)\n",
    "            m is features dimension.\n",
    "        :return e: (np.array) (n, 1)\n",
    "            whether the event occurs? (1: occurs; 0: others)\n",
    "        :return y: (np.array) (n, 1)\n",
    "            the time of event e.\n",
    "        '''\n",
    "        split = 'train' if is_train else 'test'\n",
    "        with h5py.File(h5_file, 'r') as f:\n",
    "            X = f[split]['x'][()]\n",
    "            e = f[split]['e'][()].reshape(-1, 1)\n",
    "            y = f[split]['t'][()].reshape(-1, 1)\n",
    "        return X, e, y\n",
    "\n",
    "    def _normalize(self):\n",
    "        ''' Performs normalizing X data. '''\n",
    "        self.X = (self.X-self.X.min(axis=0)) / (self.X.max(axis=0)-self.X.min(axis=0))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        ''' Performs constructing torch.Tensor object'''\n",
    "        # gets data with index of item\n",
    "        X_item = self.X[item] # (m)\n",
    "        e_item = self.e[item] # (1)\n",
    "        y_item = self.y[item] # (1)\n",
    "        # constructs torch.Tensor object\n",
    "        X_tensor = torch.from_numpy(X_item)\n",
    "        e_tensor = torch.from_numpy(e_item)\n",
    "        y_tensor = torch.from_numpy(y_item)\n",
    "        return X_tensor, y_tensor, e_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcefbaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> load 1523 samples\n",
      "=> load 381 samples\n",
      "Training dataset length: 1523\n",
      "X_sample shape: torch.Size([9])\n",
      "y_sample shape: torch.Size([1])\n",
      "e_sample shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 定义数据文件路径\n",
    "h5_file = './data/metabric/metabric_IHC4_clinical_train_test.h5'\n",
    "\n",
    "\n",
    "# 创建训练集数据集实例\n",
    "train_dataset = SurvivalDataset(h5_file, is_train=True)\n",
    "test_dataset = SurvivalDataset(h5_file, is_train=False)\n",
    "# 可选：如果需要，你可以查看数据集的长度\n",
    "print(\"Training dataset length:\", len(train_dataset))\n",
    "\n",
    "# 可以通过索引访问数据集中的数据\n",
    "# 假设想访问第一个样本的数据\n",
    "X_sample, y_sample, e_sample = train_dataset[0]\n",
    "\n",
    "# 打印样本数据的形状（假设m为特征的维度）\n",
    "print(\"X_sample shape:\", X_sample.shape)  # 应该是 (m,)\n",
    "print(\"y_sample shape:\", y_sample.shape)  # 应该是 (1,)\n",
    "print(\"e_sample shape:\", e_sample.shape)  # 应该是 (1,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65206a7f",
   "metadata": {},
   "source": [
    "## train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab76663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "X_batch shape: torch.Size([1523, 9])\n",
      "y_batch shape: torch.Size([1523, 1])\n",
      "e_batch shape: torch.Size([1523, 1])\n"
     ]
    }
   ],
   "source": [
    "# 定义批次大小（batch size）\n",
    "#batch_size = 32\n",
    "\n",
    "# 创建训练集数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_dataset.__len__(), shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_dataset.__len__(), shuffle=True)\n",
    "# 遍历数据加载器中的每一个批次\n",
    "for batch_idx, (X_batch, y_batch, e_batch) in enumerate(train_loader):\n",
    "    # 在这里执行训练代码，例如：\n",
    "    # optimizer.zero_grad()\n",
    "    # outputs = model(X_batch)\n",
    "    # loss = criterion(outputs, y_batch, e_batch)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    \n",
    "    # 可以根据需要打印每个批次的数据形状\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"X_batch shape:\", X_batch.shape)  # 应该是 (batch_size, m)\n",
    "    print(\"y_batch shape:\", y_batch.shape)  # 应该是 (batch_size, 1)\n",
    "    print(\"e_batch shape:\", e_batch.shape)  # 应该是 (batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba0023",
   "metadata": {},
   "source": [
    "## test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ab2784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "X_batch shape: torch.Size([381, 9])\n",
      "y_batch shape: torch.Size([381, 1])\n",
      "e_batch shape: torch.Size([381, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (X_test_batch, y_test_batch, e_test_batch) in enumerate(test_loader):\n",
    "    # 在这里执行训练代码，例如：\n",
    "    # optimizer.zero_grad()\n",
    "    # outputs = model(X_batch)\n",
    "    # loss = criterion(outputs, y_batch, e_batch)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    \n",
    "    # 可以根据需要打印每个批次的数据形状\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"X_batch shape:\", X_test_batch.shape)  # 应该是 (batch_size, m)\n",
    "    print(\"y_batch shape:\", y_test_batch.shape)  # 应该是 (batch_size, 1)\n",
    "    print(\"e_batch shape:\", e_test_batch.shape)  # 应该是 (batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8548f98",
   "metadata": {},
   "source": [
    "## C_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f520f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.utils import concordance_index\n",
    "def c_index(risk_pred, y, e):\n",
    "    ''' Performs calculating c-index\n",
    "\n",
    "    :param risk_pred: (np.ndarray or torch.Tensor) model prediction   模型预测\n",
    "    :param y: (np.ndarray or torch.Tensor) the times of event    事件e的时间\n",
    "    :param e: (np.ndarray or torch.Tensor) flag that records whether the event occurs   标记，记录事件是否发生\n",
    "    :return c_index: the c_index is calculated by (risk_pred, y, e)   返回计算的c指数\n",
    "    '''\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = y.detach().cpu().numpy()\n",
    "    if not isinstance(risk_pred, np.ndarray):\n",
    "        risk_pred = risk_pred.detach().cpu().numpy()\n",
    "    if not isinstance(e, np.ndarray):\n",
    "        e = e.detach().cpu().numpy()\n",
    "    return concordance_index(y, risk_pred, e)  # 直接存在计算c指数的函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68807fe1",
   "metadata": {},
   "source": [
    "## 随机生存森林"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cffea91",
   "metadata": {},
   "source": [
    "随机生存森林预测的结果是生存时间，所以在进行C_index预测的时候，为了和risk_predict区别开来需要理解为 生存时间越长 所对应的生存风险越小。所以实际上这里不需要加负号，但是在deepSurv中需要给数据加上负号来得到对应于生存时间的生存风险"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab80e2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomSurvivalForest(min_samples_leaf=15, min_samples_split=10, n_jobs=-1,\n",
      "                     random_state=42)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv\n",
    "\n",
    "# 假设你已经有了X_batch, y_batch和e_batch\n",
    "# 将数据从张量转换为numpy数组\n",
    "X_batch_np = X_batch.numpy()\n",
    "y_batch_np = y_batch.numpy().flatten()\n",
    "e_batch_np = e_batch.numpy().flatten()\n",
    "\n",
    "# 创建生存数据结构\n",
    "# Surv函数接受两个参数：事件指示（事件发生为True，未发生为False）和生存时间\n",
    "surv_data = Surv.from_arrays(event=e_batch_np, time=y_batch_np)\n",
    "\n",
    "# 将特征矩阵转换为DataFrame\n",
    "X_batch_df = pd.DataFrame(X_batch_np)\n",
    "\n",
    "# 训练RSF模型\n",
    "rsf = RandomSurvivalForest(n_estimators=100, min_samples_split=10, min_samples_leaf=15, n_jobs=-1, random_state=42)\n",
    "rsf.fit(X_batch_df, surv_data)\n",
    "\n",
    "# 打印模型信息\n",
    "print(rsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5df36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6458527300188277"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将测试数据从张量转换为numpy数组\n",
    "X_test_batch_np = X_test_batch.numpy()\n",
    "\n",
    "# 将特征矩阵转换为DataFrame\n",
    "X_test_batch_df = pd.DataFrame(X_test_batch_np)\n",
    "\n",
    "# 使用训练好的RSF模型进行预测\n",
    "# predict_survival_function 返回的是一个生成器\n",
    "surv_funcs = rsf.predict_survival_function(X_test_batch_df)\n",
    "\n",
    "# 定义你希望使用的生存概率阈值\n",
    "p = 0.5\n",
    "\n",
    "# 计算每个样本的指定生存概率时的生存时间\n",
    "# 例如，生存概率为p时的时间点\n",
    "specified_surv_times = np.array([np.interp(p, sf.y[::-1], sf.x[::-1]) for sf in surv_funcs])\n",
    "tensor = torch.tensor(specified_surv_times, dtype=torch.float32)\n",
    "valid_c = c_index(specified_surv_times,y_test_batch,e_test_batch)\n",
    "valid_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35bb63",
   "metadata": {},
   "source": [
    "## COX比例风险模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "369a8da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index: 0.6335216104938655\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 将数据从张量转换为numpy数组\n",
    "X_batch_np = X_batch.numpy()\n",
    "y_batch_np = y_batch.numpy().flatten()\n",
    "e_batch_np = e_batch.numpy().flatten().astype(bool)  # 将事件指示转换为布尔类型\n",
    "\n",
    "# 创建生存数据结构\n",
    "surv_data = Surv.from_arrays(event=e_batch_np, time=y_batch_np)\n",
    "\n",
    "# 将特征矩阵转换为DataFrame\n",
    "X_batch_df = pd.DataFrame(X_batch_np)\n",
    "\n",
    "# 训练Cox比例风险模型\n",
    "cox = CoxPHSurvivalAnalysis()\n",
    "cox.fit(X_batch_df, surv_data)\n",
    "\n",
    "# 将测试数据从张量转换为numpy数组\n",
    "X_test_batch_np = X_test_batch.numpy()\n",
    "y_test_batch_np = y_test_batch.numpy().flatten()\n",
    "e_test_batch_np = e_test_batch.numpy().flatten().astype(bool)  # 将事件指示转换为布尔类型\n",
    "\n",
    "# 将特征矩阵转换为DataFrame\n",
    "X_test_batch_df = pd.DataFrame(X_test_batch_np)\n",
    "\n",
    "# 使用训练好的Cox模型进行预测\n",
    "predicted_survival = cox.predict_survival_function(X_test_batch_df)\n",
    "\n",
    "# 选择生存概率阈值 p\n",
    "p = 0.5\n",
    "\n",
    "# 计算每个样本在指定生存概率时的生存时间\n",
    "specified_surv_times = np.array([np.interp(p, sf.y[::-1], sf.x[::-1]) for sf in predicted_survival])\n",
    "\n",
    "# 计算C-index\n",
    "c_index = concordance_index_censored(e_test_batch_np, y_test_batch_np, -specified_surv_times)\n",
    "print(\"C-index:\", c_index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202f97d",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3f474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index: 0.641756150042414\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.svm import FastSurvivalSVM\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "# 假设你已经有了X_batch, y_batch和e_batch\n",
    "# 将数据从张量转换为numpy数组\n",
    "X_batch_np = X_batch.numpy()\n",
    "y_batch_np = y_batch.numpy().flatten()\n",
    "e_batch_np = e_batch.numpy().flatten().astype(bool)  # 将事件指示转换为布尔类型\n",
    "\n",
    "# 创建生存数据结构\n",
    "surv_data = Surv.from_arrays(event=e_batch_np, time=y_batch_np)\n",
    "\n",
    "# 训练FastKernelSurvivalSVM模型，选择多项式核\n",
    "svm = FastSurvivalSVM()\n",
    "svm.fit(X_batch_np, surv_data)\n",
    "\n",
    "# 将测试数据从张量转换为numpy数组\n",
    "X_test_batch_np = X_test_batch.numpy()\n",
    "y_test_batch_np = y_test_batch.numpy().flatten()\n",
    "e_test_batch_np = e_test_batch.numpy().flatten().astype(bool)  # 将事件指示转换为布尔类型\n",
    "# 使用训练好的模型进行预测\n",
    "predicted_risk = svm.predict(X_test_batch_np)\n",
    "\n",
    "# 计算C-index\n",
    "c_index = concordance_index_censored(e_test_batch_np, y_test_batch_np, predicted_risk)\n",
    "print(\"C-index:\", c_index[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
