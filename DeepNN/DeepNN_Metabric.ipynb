{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01676cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SurvivalDataset(Dataset):\n",
    "    ''' The dataset class performs loading data from .h5 file. '''\n",
    "    def __init__(self, h5_file, is_train):\n",
    "        ''' Loading data from .h5 file based on (h5_file, is_train).\n",
    "\n",
    "        :param h5_file: (String) the path of .h5 file\n",
    "        :param is_train: (bool) which kind of data to be loaded?\n",
    "                is_train=True: loading train data\n",
    "                is_train=False: loading test data\n",
    "        '''\n",
    "        # loads data\n",
    "        self.X, self.e, self.y = \\\n",
    "            self._read_h5_file(h5_file, is_train)\n",
    "        # normalizes data\n",
    "        self._normalize()\n",
    "\n",
    "        print('=> load {} samples'.format(self.X.shape[0]))\n",
    "\n",
    "    def _read_h5_file(self, h5_file, is_train):\n",
    "        ''' The function to parsing data from .h5 file.\n",
    "\n",
    "        :return X: (np.array) (n, m)\n",
    "            m is features dimension.\n",
    "        :return e: (np.array) (n, 1)\n",
    "            whether the event occurs? (1: occurs; 0: others)\n",
    "        :return y: (np.array) (n, 1)\n",
    "            the time of event e.\n",
    "        '''\n",
    "        split = 'train' if is_train else 'test'\n",
    "        with h5py.File(h5_file, 'r') as f:\n",
    "            X = f[split]['x'][()]\n",
    "            e = f[split]['e'][()].reshape(-1, 1)\n",
    "            y = f[split]['t'][()].reshape(-1, 1)\n",
    "        return X, e, y\n",
    "\n",
    "    def _normalize(self):\n",
    "        ''' Performs normalizing X data. '''\n",
    "        self.X = (self.X-self.X.min(axis=0)) / (self.X.max(axis=0)-self.X.min(axis=0))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        ''' Performs constructing torch.Tensor object'''\n",
    "        # gets data with index of item\n",
    "        X_item = self.X[item] # (m)\n",
    "        e_item = self.e[item] # (1)\n",
    "        y_item = self.y[item] # (1)\n",
    "        # constructs torch.Tensor object\n",
    "        X_tensor = torch.from_numpy(X_item)\n",
    "        e_tensor = torch.from_numpy(e_item)\n",
    "        y_tensor = torch.from_numpy(y_item)\n",
    "        return X_tensor, y_tensor, e_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef83721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> load 1523 samples\n",
      "=> load 381 samples\n",
      "Training dataset length: 1523\n",
      "X_sample shape: torch.Size([9])\n",
      "y_sample shape: torch.Size([1])\n",
      "e_sample shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 定义数据文件路径\n",
    "h5_file = './data/metabric/metabric_IHC4_clinical_train_test.h5'\n",
    "\n",
    "\n",
    "# 创建训练集数据集实例\n",
    "train_dataset = SurvivalDataset(h5_file, is_train=True)\n",
    "test_dataset = SurvivalDataset(h5_file, is_train=False)\n",
    "# 可选：如果需要，你可以查看数据集的长度\n",
    "print(\"Training dataset length:\", len(train_dataset))\n",
    "\n",
    "# 可以通过索引访问数据集中的数据\n",
    "# 假设想访问第一个样本的数据\n",
    "X_sample, y_sample, e_sample = train_dataset[0]\n",
    "\n",
    "# 打印样本数据的形状（假设m为特征的维度）\n",
    "print(\"X_sample shape:\", X_sample.shape)  # 应该是 (m,)\n",
    "print(\"y_sample shape:\", y_sample.shape)  # 应该是 (1,)\n",
    "print(\"e_sample shape:\", e_sample.shape)  # 应该是 (1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0f10a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "X_batch shape: torch.Size([1523, 9])\n",
      "y_batch shape: torch.Size([1523, 1])\n",
      "e_batch shape: torch.Size([1523, 1])\n"
     ]
    }
   ],
   "source": [
    "# 定义批次大小（batch size）\n",
    "#batch_size = 32\n",
    "\n",
    "# 创建训练集数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_dataset.__len__(), shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_dataset.__len__(), shuffle=True)\n",
    "# 遍历数据加载器中的每一个批次\n",
    "for batch_idx, (X_batch, y_batch, e_batch) in enumerate(train_loader):\n",
    "    # 在这里执行训练代码，例如：\n",
    "    # optimizer.zero_grad()\n",
    "    # outputs = model(X_batch)\n",
    "    # loss = criterion(outputs, y_batch, e_batch)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    \n",
    "    # 可以根据需要打印每个批次的数据形状\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"X_batch shape:\", X_batch.shape)  # 应该是 (batch_size, m)\n",
    "    print(\"y_batch shape:\", y_batch.shape)  # 应该是 (batch_size, 1)\n",
    "    print(\"e_batch shape:\", e_batch.shape)  # 应该是 (batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82bad9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.utils import concordance_index\n",
    "def c_index(risk_pred, y, e):\n",
    "    ''' Performs calculating c-index\n",
    "\n",
    "    :param risk_pred: (np.ndarray or torch.Tensor) model prediction   模型预测\n",
    "    :param y: (np.ndarray or torch.Tensor) the times of event    事件e的时间\n",
    "    :param e: (np.ndarray or torch.Tensor) flag that records whether the event occurs   标记，记录事件是否发生\n",
    "    :return c_index: the c_index is calculated by (risk_pred, y, e)   返回计算的c指数\n",
    "    '''\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = y.detach().cpu().numpy()\n",
    "    if not isinstance(risk_pred, np.ndarray):\n",
    "        risk_pred = risk_pred.detach().cpu().numpy()\n",
    "    if not isinstance(e, np.ndarray):\n",
    "        e = e.detach().cpu().numpy()\n",
    "    return concordance_index(y, risk_pred, e)  # 直接存在计算c指数的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a91aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regularization(object):\n",
    "    #### 初始化\n",
    "    def __init__(self, order, weight_decay):\n",
    "        ''' The initialization of Regularization class正则化类的初始化\n",
    "\n",
    "        :param order: (int) norm order number范数\n",
    "        :param weight_decay: (float) weight decay rate权重衰减率（权重衰降的强度）\n",
    "        :param p:默认求2范数，除非设定p=1（并未使用到）\n",
    "        '''\n",
    "        super(Regularization, self).__init__()  # 集成父类的属性和方法\n",
    "        # 将传递的属性保存在self中\n",
    "        self.order = order  # 范数\n",
    "        self.weight_decay = weight_decay  # 权重衰减率\n",
    "\n",
    "    ### 用于计算模型的正则化损失\n",
    "    def __call__(self, model):  # model表示需要正则化的模型\n",
    "        ''' Performs calculates regularization(self.order) loss for model.\n",
    "\n",
    "        :param model: (torch.nn.Module object)\n",
    "        :return reg_loss: (torch.Tensor) the regularization(self.order) loss返回正则化的损失\n",
    "        '''\n",
    "        reg_loss = 0\n",
    "        for name, w in model.named_parameters():  # 遍历模型当中的参数\n",
    "            if 'weight' in name:  # 如果存在weight相关字眼，就证明时需要正则化的参数，那么就计算该参数的范数\n",
    "                reg_loss = reg_loss + torch.norm(w, p=self.order)  # torch.norm计算参数范数\n",
    "        reg_loss = self.weight_decay * reg_loss  # 最后将计算的范数乘以权重衰减率 self.weight_decay，得到正则化损失 reg_loss\n",
    "        return reg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec2ac891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class DeepNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(9, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe74d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeLogLikelihood(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NegativeLogLikelihood, self).__init__()\n",
    "        self.L2_reg = 0.001\n",
    "        self.reg = Regularization(order=2, weight_decay=self.L2_reg )\n",
    "\n",
    "    def forward(self, risk_pred, y, e, model):\n",
    "        # 确定设备，这里假设所有输入张量都应该在同一个设备上\n",
    "        device = risk_pred.device\n",
    "\n",
    "        # 确保所有输入张量都在正确的设备上\n",
    "        y = y.to(device)\n",
    "        e = e.to(device)\n",
    "        model = model.to(device)  # 假设model也需要被移动到正确的设备\n",
    "\n",
    "        # 创建蒙版mask，确保它也在正确的设备上\n",
    "        mask = torch.ones(y.shape[0], y.shape[0], device=device)\n",
    "        mask[(y.T - y) > 0] = 0\n",
    "\n",
    "        # 确保风险预测指数化操作也在正确的设备上执行\n",
    "        log_loss = torch.exp(risk_pred.to(device)) * mask\n",
    "\n",
    "        # 接下来的操作...\n",
    "        log_loss = torch.sum(log_loss, dim=0) / torch.sum(mask, dim=0)\n",
    "        log_loss = torch.log(log_loss).reshape(-1, 1)\n",
    "\n",
    "        neg_log_loss = -torch.sum((risk_pred - log_loss) * e) / torch.sum(e)\n",
    "        l2_loss = self.reg(model)  # 确保正则化操作也在正确的设备上执行\n",
    "\n",
    "        return neg_log_loss + l2_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "384f221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, lr, lr_decay_rate):\n",
    "    ''' Adjusts learning rate according to (epoch, lr and lr_decay_rate)\n",
    "\n",
    "    :param optimizer: (torch.optim object) 优化器\n",
    "    :param epoch: (int) 迭代次数\n",
    "    :param lr: (float) the initial learning rate 学习率\n",
    "    :param lr_decay_rate: (float) learning rate decay rate 学习率衰减率\n",
    "    :return lr_: (float) updated learning rate 返回一个更新好的学习率\n",
    "    '''\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr / (1 + epoch * lr_decay_rate)\n",
    "    return optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f610d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, test_loader, device):\n",
    "\n",
    "    # training\n",
    "    best_c_index = 0  # 定义一个变量 best_c_index，用于记录训练过程中最优的 c-index\n",
    "    flag = 0  # 定义一个变量 flag，用于记录训练过程中最优的 c-index 持续多少个 epoch 未更新，以便进行早停策略\n",
    "    for epoch in range(1, 501):\n",
    "        # adjusts learning rate\n",
    "        lr = adjust_learning_rate(optimizer, epoch, 0.047, 4.169e-3)\n",
    "        # train step\n",
    "        model.train()  # 模型调整到训练模式\n",
    "        for X, y, e in train_loader:  # 整个过程重复，直到处理完train_loader中所有数据\n",
    "            # 将数据移动到指定设备\n",
    "            X, y, e = X.to(device), y.to(device), e.to(device)\n",
    "            # makes predictions 做预测\n",
    "            risk_pred = model(X)  # 风险预测值\n",
    "            train_loss = criterion(risk_pred, y, e, model)  # 训练损失函数\n",
    "            train_c = c_index(-risk_pred, y, e)  # 训练出来的c指数\n",
    "            # updates parameters 更新参数\n",
    "            optimizer.zero_grad()  # 清空当前的梯度\n",
    "            train_loss.backward()  # 计算损失函数的梯度\n",
    "            optimizer.step()  # 更新模型\n",
    "        \n",
    "        # valid step\n",
    "        model.eval()  # 模型调整到测试模式\n",
    "        for X, y, e in test_loader:\n",
    "            # 将数据移动到指定设备\n",
    "            X, y, e = X.to(device), y.to(device), e.to(device)\n",
    "            # makes predictions 做预测\n",
    "            with torch.no_grad():  # 因为测试模式下，无需计算梯度，因此关闭梯度计算，以提高计算速度\n",
    "                risk_pred = model(X)  # 风险预测\n",
    "                valid_loss = criterion(risk_pred, y, e, model)  # 计算损失函数\n",
    "                valid_c = c_index(-risk_pred, y, e)  # 测试的c指数\n",
    "                if best_c_index < valid_c:\n",
    "                    best_c_index = valid_c\n",
    "                    flag = 0  # 如果当前c指数>最大c指数，更新c指数，flag=0\n",
    "                    # saves the best model 保存预测效果最好的那一次迭代\n",
    "                    torch.save({  # 并且将当前的模型保存下来\n",
    "                        'model': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'epoch': epoch}, 'test.pth')\n",
    "                else:\n",
    "                    flag += 1\n",
    "                    if flag >= 50:\n",
    "                        print(f\"Early stopping at epoch {epoch}, best c-index: {best_c_index}\")\n",
    "                        return best_c_index\n",
    "        # notes that, train loader and valid loader both have one batch!!!注意，train loader和valid loader都有一个批次!!\n",
    "        print('\\rEpoch: {}\\tLoss: {:.8f}({:.8f})\\tc-index: {:.8f}({:.8f})\\tlr: {:g}'.format(\n",
    "            epoch, train_loss.item(), valid_loss.item(), train_c, valid_c, lr), end='', flush=False)\n",
    "        print(f\"\\nFlag: {flag}, Best c-index: {best_c_index}\")\n",
    "    return best_c_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82694ef6",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "729f3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=32, bias=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "    (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.25, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.25, inplace=False)\n",
       "    (12): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepNN()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b46cbce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NegativeLogLikelihood().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32adaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer= optim.Adam(model.parameters(), lr= 0.047)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "facbfc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tLoss: 0.08838299(0.02592209)\tc-index: 0.52709145(0.54738998)\tlr: 0.0468049\n",
      "Flag: 0, Best c-index: 0.5473899819998759\n",
      "Epoch: 2\tLoss: 0.10371502(0.03089985)\tc-index: 0.54099176(0.56909358)\tlr: 0.0466114\n",
      "Flag: 0, Best c-index: 0.5690935799557238\n",
      "Epoch: 3\tLoss: 0.05275608(0.03290936)\tc-index: 0.54495002(0.55295554)\tlr: 0.0464194\n",
      "Flag: 1, Best c-index: 0.5690935799557238\n",
      "Epoch: 4\tLoss: 0.01121316(0.03010841)\tc-index: 0.56563541(0.53648646)\tlr: 0.0462291\n",
      "Flag: 2, Best c-index: 0.5690935799557238\n",
      "Epoch: 5\tLoss: -0.01151318(0.02115018)\tc-index: 0.58362382(0.54602446)\tlr: 0.0460403\n",
      "Flag: 3, Best c-index: 0.5690935799557238\n",
      "Epoch: 6\tLoss: -0.04087124(0.00687179)\tc-index: 0.60563976(0.56164525)\tlr: 0.045853\n",
      "Flag: 4, Best c-index: 0.5690935799557238\n",
      "Epoch: 7\tLoss: -0.03603861(-0.00917282)\tc-index: 0.60816113(0.57577638)\tlr: 0.0456673\n",
      "Flag: 0, Best c-index: 0.5757763846647218\n",
      "Epoch: 8\tLoss: -0.04046441(-0.02614360)\tc-index: 0.61905286(0.59930068)\tlr: 0.045483\n",
      "Flag: 0, Best c-index: 0.5993006848323091\n",
      "Epoch: 9\tLoss: -0.04627874(-0.03741788)\tc-index: 0.63153853(0.60929386)\tlr: 0.0453003\n",
      "Flag: 0, Best c-index: 0.6092938571990152\n",
      "Epoch: 10\tLoss: -0.04921712(-0.04273866)\tc-index: 0.62871420(0.60923179)\tlr: 0.045119\n",
      "Flag: 1, Best c-index: 0.6092938571990152\n",
      "Epoch: 11\tLoss: -0.07277203(-0.04634770)\tc-index: 0.63300758(0.60885937)\tlr: 0.0449391\n",
      "Flag: 2, Best c-index: 0.6092938571990152\n",
      "Epoch: 12\tLoss: -0.07935380(-0.05242011)\tc-index: 0.63944146(0.61084559)\tlr: 0.0447607\n",
      "Flag: 0, Best c-index: 0.6108455920385658\n",
      "Epoch: 13\tLoss: -0.07013202(-0.06070919)\tc-index: 0.63051094(0.61701115)\tlr: 0.0445837\n",
      "Flag: 0, Best c-index: 0.6170111518010469\n",
      "Epoch: 14\tLoss: -0.08028886(-0.07366529)\tc-index: 0.63871931(0.62785261)\tlr: 0.0444081\n",
      "Flag: 0, Best c-index: 0.6278526058800405\n",
      "Epoch: 15\tLoss: -0.08645451(-0.08568501)\tc-index: 0.64384614(0.62998366)\tlr: 0.0442338\n",
      "Flag: 0, Best c-index: 0.6299836550596901\n",
      "Epoch: 16\tLoss: -0.06458130(-0.09408548)\tc-index: 0.63124670(0.63374920)\tlr: 0.044061\n",
      "Flag: 0, Best c-index: 0.6337491982703329\n",
      "Epoch: 17\tLoss: -0.08221431(-0.09847189)\tc-index: 0.64673230(0.63366644)\tlr: 0.0438894\n",
      "Flag: 1, Best c-index: 0.6337491982703329\n",
      "Epoch: 18\tLoss: -0.08183581(-0.09771532)\tc-index: 0.64521997(0.62998366)\tlr: 0.0437192\n",
      "Flag: 2, Best c-index: 0.6337491982703329\n",
      "Epoch: 19\tLoss: -0.10044037(-0.09270076)\tc-index: 0.65016502(0.62294912)\tlr: 0.0435503\n",
      "Flag: 3, Best c-index: 0.6337491982703329\n",
      "Epoch: 20\tLoss: -0.10212514(-0.08915809)\tc-index: 0.64560516(0.61790081)\tlr: 0.0433827\n",
      "Flag: 4, Best c-index: 0.6337491982703329\n",
      "Epoch: 21\tLoss: -0.07575694(-0.08662418)\tc-index: 0.64124562(0.61647322)\tlr: 0.0432164\n",
      "Flag: 5, Best c-index: 0.6337491982703329\n",
      "Epoch: 22\tLoss: -0.09874243(-0.08779396)\tc-index: 0.64532508(0.61792150)\tlr: 0.0430514\n",
      "Flag: 6, Best c-index: 0.6337491982703329\n",
      "Epoch: 23\tLoss: -0.10422666(-0.09118257)\tc-index: 0.65088780(0.62059049)\tlr: 0.0428876\n",
      "Flag: 7, Best c-index: 0.6337491982703329\n",
      "Epoch: 24\tLoss: -0.08513671(-0.09635809)\tc-index: 0.64746435(0.62632156)\tlr: 0.0427251\n",
      "Flag: 8, Best c-index: 0.6337491982703329\n",
      "Epoch: 25\tLoss: -0.10720290(-0.10143818)\tc-index: 0.65269257(0.63294230)\tlr: 0.0425638\n",
      "Flag: 9, Best c-index: 0.6337491982703329\n",
      "Epoch: 26\tLoss: -0.10503463(-0.10604300)\tc-index: 0.65834742(0.63790785)\tlr: 0.0424037\n",
      "Flag: 0, Best c-index: 0.6379078476403286\n",
      "Epoch: 27\tLoss: -0.09498575(-0.10805582)\tc-index: 0.65320575(0.64092856)\tlr: 0.0422448\n",
      "Flag: 0, Best c-index: 0.6409285581279871\n",
      "Epoch: 28\tLoss: -0.11408429(-0.10870335)\tc-index: 0.66119896(0.63794923)\tlr: 0.0420871\n",
      "Flag: 1, Best c-index: 0.6409285581279871\n",
      "Epoch: 29\tLoss: -0.11027748(-0.10654543)\tc-index: 0.65578030(0.63296299)\tlr: 0.0419306\n",
      "Flag: 2, Best c-index: 0.6409285581279871\n",
      "Epoch: 30\tLoss: -0.10298646(-0.10443351)\tc-index: 0.65431619(0.62859744)\tlr: 0.0417752\n",
      "Flag: 3, Best c-index: 0.6409285581279871\n",
      "Epoch: 31\tLoss: -0.10279742(-0.10373978)\tc-index: 0.65495921(0.62716984)\tlr: 0.041621\n",
      "Flag: 4, Best c-index: 0.6409285581279871\n",
      "Epoch: 32\tLoss: -0.10111079(-0.10451719)\tc-index: 0.64940329(0.63027331)\tlr: 0.0414679\n",
      "Flag: 5, Best c-index: 0.6409285581279871\n",
      "Epoch: 33\tLoss: -0.11042754(-0.10597411)\tc-index: 0.65651729(0.63348023)\tlr: 0.0413159\n",
      "Flag: 6, Best c-index: 0.6409285581279871\n",
      "Epoch: 34\tLoss: -0.10998720(-0.10713269)\tc-index: 0.65410350(0.63807337)\tlr: 0.041165\n",
      "Flag: 7, Best c-index: 0.6409285581279871\n",
      "Epoch: 35\tLoss: -0.11394380(-0.10933763)\tc-index: 0.65848221(0.64196305)\tlr: 0.0410153\n",
      "Flag: 0, Best c-index: 0.6419630480210209\n",
      "Epoch: 36\tLoss: -0.11948264(-0.11289378)\tc-index: 0.66120638(0.64384582)\tlr: 0.0408666\n",
      "Flag: 0, Best c-index: 0.6438458196263422\n",
      "Epoch: 37\tLoss: -0.11292920(-0.11662003)\tc-index: 0.65252811(0.64456996)\tlr: 0.040719\n",
      "Flag: 0, Best c-index: 0.6445699625514659\n",
      "Epoch: 38\tLoss: -0.11954921(-0.11799906)\tc-index: 0.65963716(0.64345271)\tlr: 0.0405724\n",
      "Flag: 1, Best c-index: 0.6445699625514659\n",
      "Epoch: 39\tLoss: -0.11034612(-0.11869760)\tc-index: 0.65578153(0.64179753)\tlr: 0.0404269\n",
      "Flag: 2, Best c-index: 0.6445699625514659\n",
      "Epoch: 40\tLoss: -0.11323245(-0.11864403)\tc-index: 0.65860834(0.63939751)\tlr: 0.0402825\n",
      "Flag: 3, Best c-index: 0.6445699625514659\n",
      "Epoch: 41\tLoss: -0.11205736(-0.11282340)\tc-index: 0.65773408(0.63544576)\tlr: 0.0401391\n",
      "Flag: 4, Best c-index: 0.6445699625514659\n",
      "Epoch: 42\tLoss: -0.12945488(-0.10808641)\tc-index: 0.66299446(0.63358368)\tlr: 0.0399967\n",
      "Flag: 5, Best c-index: 0.6445699625514659\n",
      "Epoch: 43\tLoss: -0.13211101(-0.10678546)\tc-index: 0.66446722(0.63472162)\tlr: 0.0398553\n",
      "Flag: 6, Best c-index: 0.6445699625514659\n",
      "Epoch: 44\tLoss: -0.14054433(-0.10957824)\tc-index: 0.66943329(0.63788716)\tlr: 0.0397149\n",
      "Flag: 7, Best c-index: 0.6445699625514659\n",
      "Epoch: 45\tLoss: -0.11810742(-0.11292818)\tc-index: 0.66263091(0.63962510)\tlr: 0.0395754\n",
      "Flag: 8, Best c-index: 0.6445699625514659\n",
      "Epoch: 46\tLoss: -0.11034130(-0.11637588)\tc-index: 0.65535491(0.64074235)\tlr: 0.039437\n",
      "Flag: 9, Best c-index: 0.6445699625514659\n",
      "Epoch: 47\tLoss: -0.14679766(-0.11845057)\tc-index: 0.66985496(0.64096994)\tlr: 0.0392995\n",
      "Flag: 10, Best c-index: 0.6445699625514659\n",
      "Epoch: 48\tLoss: -0.12890553(-0.11868455)\tc-index: 0.65973733(0.64105270)\tlr: 0.039163\n",
      "Flag: 11, Best c-index: 0.6445699625514659\n",
      "Epoch: 49\tLoss: -0.12981386(-0.11899795)\tc-index: 0.66595358(0.64078373)\tlr: 0.0390274\n",
      "Flag: 12, Best c-index: 0.6445699625514659\n",
      "Epoch: 50\tLoss: -0.13263193(-0.11722153)\tc-index: 0.66803225(0.64003890)\tlr: 0.0388928\n",
      "Flag: 13, Best c-index: 0.6445699625514659\n",
      "Epoch: 51\tLoss: -0.13527611(-0.11258056)\tc-index: 0.66372280(0.63805268)\tlr: 0.0387591\n",
      "Flag: 14, Best c-index: 0.6445699625514659\n",
      "Epoch: 52\tLoss: -0.13384181(-0.10821435)\tc-index: 0.66374753(0.63689405)\tlr: 0.0386263\n",
      "Flag: 15, Best c-index: 0.6445699625514659\n",
      "Epoch: 53\tLoss: -0.13465968(-0.10767455)\tc-index: 0.65986469(0.63828026)\tlr: 0.0384944\n",
      "Flag: 16, Best c-index: 0.6445699625514659\n",
      "Epoch: 54\tLoss: -0.13756347(-0.11020933)\tc-index: 0.66393549(0.64291478)\tlr: 0.0383634\n",
      "Flag: 17, Best c-index: 0.6445699625514659\n",
      "Epoch: 55\tLoss: -0.14578718(-0.11401021)\tc-index: 0.66896463(0.64690791)\tlr: 0.0382333\n",
      "Flag: 0, Best c-index: 0.6469079097097221\n",
      "Epoch: 56\tLoss: -0.15320663(-0.11900239)\tc-index: 0.67139820(0.65011483)\tlr: 0.0381041\n",
      "Flag: 0, Best c-index: 0.6501148283781267\n",
      "Epoch: 57\tLoss: -0.14669485(-0.12271443)\tc-index: 0.67356963(0.64889413)\tlr: 0.0379757\n",
      "Flag: 1, Best c-index: 0.6501148283781267\n",
      "Epoch: 58\tLoss: -0.13297778(-0.12166893)\tc-index: 0.67132401(0.64605963)\tlr: 0.0378482\n",
      "Flag: 2, Best c-index: 0.6501148283781267\n",
      "Epoch: 59\tLoss: -0.14508210(-0.11844052)\tc-index: 0.67491749(0.64314237)\tlr: 0.0377216\n",
      "Flag: 3, Best c-index: 0.6501148283781267\n",
      "Epoch: 60\tLoss: -0.13907903(-0.11068390)\tc-index: 0.67065379(0.63792854)\tlr: 0.0375958\n",
      "Flag: 4, Best c-index: 0.6501148283781267\n",
      "Epoch: 61\tLoss: -0.15438093(-0.10526189)\tc-index: 0.66987351(0.63641818)\tlr: 0.0374708\n",
      "Flag: 5, Best c-index: 0.6501148283781267\n",
      "Epoch: 62\tLoss: -0.14323013(-0.10049522)\tc-index: 0.66559126(0.63412161)\tlr: 0.0373467\n",
      "Flag: 6, Best c-index: 0.6501148283781267\n",
      "Epoch: 63\tLoss: -0.14128809(-0.10009956)\tc-index: 0.66628869(0.63465955)\tlr: 0.0372234\n",
      "Flag: 7, Best c-index: 0.6501148283781267\n",
      "Epoch: 64\tLoss: -0.15313299(-0.10276079)\tc-index: 0.66926017(0.63648025)\tlr: 0.0371009\n",
      "Flag: 8, Best c-index: 0.6501148283781267\n",
      "Epoch: 65\tLoss: -0.14322737(-0.10708824)\tc-index: 0.66932571(0.63776302)\tlr: 0.0369792\n",
      "Flag: 9, Best c-index: 0.6501148283781267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66\tLoss: -0.14400610(-0.11278962)\tc-index: 0.66826844(0.64008028)\tlr: 0.0368583\n",
      "Flag: 10, Best c-index: 0.6501148283781267\n",
      "Epoch: 67\tLoss: -0.14895535(-0.11548753)\tc-index: 0.67300080(0.64096994)\tlr: 0.0367382\n",
      "Flag: 11, Best c-index: 0.6501148283781267\n",
      "Epoch: 68\tLoss: -0.14394076(-0.11114277)\tc-index: 0.67409146(0.63981131)\tlr: 0.0366188\n",
      "Flag: 12, Best c-index: 0.6501148283781267\n",
      "Epoch: 69\tLoss: -0.14615718(-0.10442808)\tc-index: 0.67343360(0.63817682)\tlr: 0.0365003\n",
      "Flag: 13, Best c-index: 0.6501148283781267\n",
      "Epoch: 70\tLoss: -0.15412444(-0.09717487)\tc-index: 0.67532309(0.63697681)\tlr: 0.0363825\n",
      "Flag: 14, Best c-index: 0.6501148283781267\n",
      "Epoch: 71\tLoss: -0.15131021(-0.09376492)\tc-index: 0.66960270(0.63610784)\tlr: 0.0362655\n",
      "Flag: 15, Best c-index: 0.6501148283781267\n",
      "Epoch: 72\tLoss: -0.16086061(-0.09416597)\tc-index: 0.67566562(0.63614921)\tlr: 0.0361492\n",
      "Flag: 16, Best c-index: 0.6501148283781267\n",
      "Epoch: 73\tLoss: -0.15959318(-0.09611229)\tc-index: 0.67145014(0.63513541)\tlr: 0.0360336\n",
      "Flag: 17, Best c-index: 0.6501148283781267\n",
      "Epoch: 74\tLoss: -0.15632975(-0.09874694)\tc-index: 0.67346823(0.63552852)\tlr: 0.0359188\n",
      "Flag: 18, Best c-index: 0.6501148283781267\n",
      "Epoch: 75\tLoss: -0.14120682(-0.09719968)\tc-index: 0.66916619(0.63588025)\tlr: 0.0358047\n",
      "Flag: 19, Best c-index: 0.6501148283781267\n",
      "Epoch: 76\tLoss: -0.15710518(-0.09594216)\tc-index: 0.67244867(0.63749405)\tlr: 0.0356914\n",
      "Flag: 20, Best c-index: 0.6501148283781267\n",
      "Epoch: 77\tLoss: -0.16481215(-0.09801488)\tc-index: 0.67588696(0.64111477)\tlr: 0.0355788\n",
      "Flag: 21, Best c-index: 0.6501148283781267\n",
      "Epoch: 78\tLoss: -0.15548471(-0.09812492)\tc-index: 0.67646691(0.64169408)\tlr: 0.0354668\n",
      "Flag: 22, Best c-index: 0.6501148283781267\n",
      "Epoch: 79\tLoss: -0.16331726(-0.09736397)\tc-index: 0.67494717(0.64237684)\tlr: 0.0353556\n",
      "Flag: 23, Best c-index: 0.6501148283781267\n",
      "Epoch: 80\tLoss: -0.15489525(-0.09833754)\tc-index: 0.67127331(0.64272857)\tlr: 0.0352451\n",
      "Flag: 24, Best c-index: 0.6501148283781267\n",
      "Epoch: 81\tLoss: -0.16047937(-0.09900438)\tc-index: 0.67560750(0.64266650)\tlr: 0.0351352\n",
      "Flag: 25, Best c-index: 0.6501148283781267\n",
      "Epoch: 82\tLoss: -0.16719449(-0.10124619)\tc-index: 0.67839597(0.64177684)\tlr: 0.0350261\n",
      "Flag: 26, Best c-index: 0.6501148283781267\n",
      "Epoch: 83\tLoss: -0.17141008(-0.10360940)\tc-index: 0.67756746(0.64208719)\tlr: 0.0349176\n",
      "Flag: 27, Best c-index: 0.6501148283781267\n",
      "Epoch: 84\tLoss: -0.16550478(-0.10936178)\tc-index: 0.67270403(0.64324582)\tlr: 0.0348098\n",
      "Flag: 28, Best c-index: 0.6501148283781267\n",
      "Epoch: 85\tLoss: -0.15643707(-0.11280461)\tc-index: 0.67658315(0.64409410)\tlr: 0.0347026\n",
      "Flag: 29, Best c-index: 0.6501148283781267\n",
      "Epoch: 86\tLoss: -0.16505539(-0.11296917)\tc-index: 0.67715569(0.64490100)\tlr: 0.0345961\n",
      "Flag: 30, Best c-index: 0.6501148283781267\n",
      "Epoch: 87\tLoss: -0.17672667(-0.11269002)\tc-index: 0.67973765(0.64440444)\tlr: 0.0344903\n",
      "Flag: 31, Best c-index: 0.6501148283781267\n",
      "Epoch: 88\tLoss: -0.16497901(-0.11233488)\tc-index: 0.67602793(0.64407341)\tlr: 0.0343851\n",
      "Flag: 32, Best c-index: 0.6501148283781267\n",
      "Epoch: 89\tLoss: -0.15827957(-0.11143383)\tc-index: 0.67341382(0.64448720)\tlr: 0.0342805\n",
      "Flag: 33, Best c-index: 0.6501148283781267\n",
      "Epoch: 90\tLoss: -0.16820362(-0.10687824)\tc-index: 0.67368339(0.64336995)\tlr: 0.0341766\n",
      "Flag: 34, Best c-index: 0.6501148283781267\n",
      "Epoch: 91\tLoss: -0.16749713(-0.10511869)\tc-index: 0.68326806(0.64148718)\tlr: 0.0340733\n",
      "Flag: 35, Best c-index: 0.6501148283781267\n",
      "Epoch: 92\tLoss: -0.15394954(-0.10600486)\tc-index: 0.67386269(0.64128028)\tlr: 0.0339706\n",
      "Flag: 36, Best c-index: 0.6501148283781267\n",
      "Epoch: 93\tLoss: -0.16616294(-0.10625528)\tc-index: 0.67776779(0.64270788)\tlr: 0.0338686\n",
      "Flag: 37, Best c-index: 0.6501148283781267\n",
      "Epoch: 94\tLoss: -0.16736276(-0.10329692)\tc-index: 0.67784693(0.64167339)\tlr: 0.0337671\n",
      "Flag: 38, Best c-index: 0.6501148283781267\n",
      "Epoch: 95\tLoss: -0.17245938(-0.10166551)\tc-index: 0.68159745(0.64185960)\tlr: 0.0336663\n",
      "Flag: 39, Best c-index: 0.6501148283781267\n",
      "Epoch: 96\tLoss: -0.17844437(-0.10051522)\tc-index: 0.67913853(0.64043200)\tlr: 0.0335661\n",
      "Flag: 40, Best c-index: 0.6501148283781267\n",
      "Epoch: 97\tLoss: -0.15608218(-0.09682228)\tc-index: 0.67545787(0.63821819)\tlr: 0.0334664\n",
      "Flag: 41, Best c-index: 0.6501148283781267\n",
      "Epoch: 98\tLoss: -0.19426079(-0.09085907)\tc-index: 0.68684423(0.63734922)\tlr: 0.0333674\n",
      "Flag: 42, Best c-index: 0.6501148283781267\n",
      "Epoch: 99\tLoss: -0.15591000(-0.09038538)\tc-index: 0.67300946(0.63627335)\tlr: 0.0332689\n",
      "Flag: 43, Best c-index: 0.6501148283781267\n",
      "Epoch: 100\tLoss: -0.16401044(-0.09084842)\tc-index: 0.67299833(0.63559059)\tlr: 0.033171\n",
      "Flag: 44, Best c-index: 0.6501148283781267\n",
      "Epoch: 101\tLoss: -0.18151434(-0.09209068)\tc-index: 0.68136374(0.63689405)\tlr: 0.0330737\n",
      "Flag: 45, Best c-index: 0.6501148283781267\n",
      "Epoch: 102\tLoss: -0.18726024(-0.09353796)\tc-index: 0.68630632(0.63900441)\tlr: 0.0329769\n",
      "Flag: 46, Best c-index: 0.6501148283781267\n",
      "Epoch: 103\tLoss: -0.18615317(-0.09411773)\tc-index: 0.68547905(0.64074235)\tlr: 0.0328808\n",
      "Flag: 47, Best c-index: 0.6501148283781267\n",
      "Epoch: 104\tLoss: -0.18470508(-0.09534196)\tc-index: 0.68076400(0.64094925)\tlr: 0.0327851\n",
      "Flag: 48, Best c-index: 0.6501148283781267\n",
      "Epoch: 105\tLoss: -0.16897559(-0.09370558)\tc-index: 0.68292182(0.64032855)\tlr: 0.0326901\n",
      "Flag: 49, Best c-index: 0.6501148283781267\n",
      "Early stopping at epoch 106, best c-index: 0.6501148283781267\n"
     ]
    }
   ],
   "source": [
    "best_c_index = train(model,criterion,optimizer,train_loader,test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d87a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.616195280392804"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_c_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
