{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01676cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SurvivalDataset(Dataset):\n",
    "    ''' The dataset class performs loading data from .h5 file. '''\n",
    "    def __init__(self, h5_file, is_train):\n",
    "        ''' Loading data from .h5 file based on (h5_file, is_train).\n",
    "\n",
    "        :param h5_file: (String) the path of .h5 file\n",
    "        :param is_train: (bool) which kind of data to be loaded?\n",
    "                is_train=True: loading train data\n",
    "                is_train=False: loading test data\n",
    "        '''\n",
    "        # loads data\n",
    "        self.X, self.e, self.y = \\\n",
    "            self._read_h5_file(h5_file, is_train)\n",
    "        # normalizes data\n",
    "        self._normalize()\n",
    "\n",
    "        print('=> load {} samples'.format(self.X.shape[0]))\n",
    "\n",
    "    def _read_h5_file(self, h5_file, is_train):\n",
    "        ''' The function to parsing data from .h5 file.\n",
    "\n",
    "        :return X: (np.array) (n, m)\n",
    "            m is features dimension.\n",
    "        :return e: (np.array) (n, 1)\n",
    "            whether the event occurs? (1: occurs; 0: others)\n",
    "        :return y: (np.array) (n, 1)\n",
    "            the time of event e.\n",
    "        '''\n",
    "        split = 'train' if is_train else 'test'\n",
    "        with h5py.File(h5_file, 'r') as f:\n",
    "            X = f[split]['x'][()]\n",
    "            e = f[split]['e'][()].reshape(-1, 1)\n",
    "            y = f[split]['t'][()].reshape(-1, 1)\n",
    "        return X, e, y\n",
    "\n",
    "    def _normalize(self):\n",
    "        ''' Performs normalizing X data. '''\n",
    "        self.X = (self.X-self.X.min(axis=0)) / (self.X.max(axis=0)-self.X.min(axis=0))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        ''' Performs constructing torch.Tensor object'''\n",
    "        # gets data with index of item\n",
    "        X_item = self.X[item] # (m)\n",
    "        e_item = self.e[item] # (1)\n",
    "        y_item = self.y[item] # (1)\n",
    "        # constructs torch.Tensor object\n",
    "        X_tensor = torch.from_numpy(X_item)\n",
    "        e_tensor = torch.from_numpy(e_item)\n",
    "        y_tensor = torch.from_numpy(y_item)\n",
    "        return X_tensor, y_tensor, e_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef83721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> load 7098 samples\n",
      "=> load 1775 samples\n",
      "Training dataset length: 7098\n",
      "X_sample shape: torch.Size([14])\n",
      "y_sample shape: torch.Size([1])\n",
      "e_sample shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 定义数据文件路径\n",
    "h5_file = './data/support/support_train_test.h5'\n",
    "\n",
    "\n",
    "# 创建训练集数据集实例\n",
    "train_dataset = SurvivalDataset(h5_file, is_train=True)\n",
    "test_dataset = SurvivalDataset(h5_file, is_train=False)\n",
    "# 可选：如果需要，你可以查看数据集的长度\n",
    "print(\"Training dataset length:\", len(train_dataset))\n",
    "\n",
    "# 可以通过索引访问数据集中的数据\n",
    "# 假设想访问第一个样本的数据\n",
    "X_sample, y_sample, e_sample = train_dataset[0]\n",
    "\n",
    "# 打印样本数据的形状（假设m为特征的维度）\n",
    "print(\"X_sample shape:\", X_sample.shape)  # 应该是 (m,)\n",
    "print(\"y_sample shape:\", y_sample.shape)  # 应该是 (1,)\n",
    "print(\"e_sample shape:\", e_sample.shape)  # 应该是 (1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0f10a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "X_batch shape: torch.Size([7098, 14])\n",
      "y_batch shape: torch.Size([7098, 1])\n",
      "e_batch shape: torch.Size([7098, 1])\n"
     ]
    }
   ],
   "source": [
    "# 定义批次大小（batch size）\n",
    "#batch_size = 32\n",
    "\n",
    "# 创建训练集数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_dataset.__len__(), shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_dataset.__len__(), shuffle=True)\n",
    "# 遍历数据加载器中的每一个批次\n",
    "for batch_idx, (X_batch, y_batch, e_batch) in enumerate(train_loader):\n",
    "    # 在这里执行训练代码，例如：\n",
    "    # optimizer.zero_grad()\n",
    "    # outputs = model(X_batch)\n",
    "    # loss = criterion(outputs, y_batch, e_batch)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    \n",
    "    # 可以根据需要打印每个批次的数据形状\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"X_batch shape:\", X_batch.shape)  # 应该是 (batch_size, m)\n",
    "    print(\"y_batch shape:\", y_batch.shape)  # 应该是 (batch_size, 1)\n",
    "    print(\"e_batch shape:\", e_batch.shape)  # 应该是 (batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82bad9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.utils import concordance_index\n",
    "def c_index(risk_pred, y, e):\n",
    "    ''' Performs calculating c-index\n",
    "\n",
    "    :param risk_pred: (np.ndarray or torch.Tensor) model prediction   模型预测\n",
    "    :param y: (np.ndarray or torch.Tensor) the times of event    事件e的时间\n",
    "    :param e: (np.ndarray or torch.Tensor) flag that records whether the event occurs   标记，记录事件是否发生\n",
    "    :return c_index: the c_index is calculated by (risk_pred, y, e)   返回计算的c指数\n",
    "    '''\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = y.detach().cpu().numpy()\n",
    "    if not isinstance(risk_pred, np.ndarray):\n",
    "        risk_pred = risk_pred.detach().cpu().numpy()\n",
    "    if not isinstance(e, np.ndarray):\n",
    "        e = e.detach().cpu().numpy()\n",
    "    return concordance_index(y, risk_pred, e)  # 直接存在计算c指数的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a91aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regularization(object):\n",
    "    #### 初始化\n",
    "    def __init__(self, order, weight_decay):\n",
    "        ''' The initialization of Regularization class正则化类的初始化\n",
    "\n",
    "        :param order: (int) norm order number范数\n",
    "        :param weight_decay: (float) weight decay rate权重衰减率（权重衰降的强度）\n",
    "        :param p:默认求2范数，除非设定p=1（并未使用到）\n",
    "        '''\n",
    "        super(Regularization, self).__init__()  # 集成父类的属性和方法\n",
    "        # 将传递的属性保存在self中\n",
    "        self.order = order  # 范数\n",
    "        self.weight_decay = weight_decay  # 权重衰减率\n",
    "\n",
    "    ### 用于计算模型的正则化损失\n",
    "    def __call__(self, model):  # model表示需要正则化的模型\n",
    "        ''' Performs calculates regularization(self.order) loss for model.\n",
    "\n",
    "        :param model: (torch.nn.Module object)\n",
    "        :return reg_loss: (torch.Tensor) the regularization(self.order) loss返回正则化的损失\n",
    "        '''\n",
    "        reg_loss = 0\n",
    "        for name, w in model.named_parameters():  # 遍历模型当中的参数\n",
    "            if 'weight' in name:  # 如果存在weight相关字眼，就证明时需要正则化的参数，那么就计算该参数的范数\n",
    "                reg_loss = reg_loss + torch.norm(w, p=self.order)  # torch.norm计算参数范数\n",
    "        reg_loss = self.weight_decay * reg_loss  # 最后将计算的范数乘以权重衰减率 self.weight_decay，得到正则化损失 reg_loss\n",
    "        return reg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec2ac891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class DeepNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(14, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe74d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeLogLikelihood(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NegativeLogLikelihood, self).__init__()\n",
    "        self.L2_reg = 0.001\n",
    "        self.reg = Regularization(order=2, weight_decay=self.L2_reg )\n",
    "\n",
    "    def forward(self, risk_pred, y, e, model):\n",
    "        # 确定设备，这里假设所有输入张量都应该在同一个设备上\n",
    "        device = risk_pred.device\n",
    "\n",
    "        # 确保所有输入张量都在正确的设备上\n",
    "        y = y.to(device)\n",
    "        e = e.to(device)\n",
    "        model = model.to(device)  # 假设model也需要被移动到正确的设备\n",
    "\n",
    "        # 创建蒙版mask，确保它也在正确的设备上\n",
    "        mask = torch.ones(y.shape[0], y.shape[0], device=device)\n",
    "        mask[(y.T - y) > 0] = 0\n",
    "\n",
    "        # 确保风险预测指数化操作也在正确的设备上执行\n",
    "        log_loss = torch.exp(risk_pred.to(device)) * mask\n",
    "\n",
    "        # 接下来的操作...\n",
    "        log_loss = torch.sum(log_loss, dim=0) / torch.sum(mask, dim=0)\n",
    "        log_loss = torch.log(log_loss).reshape(-1, 1)\n",
    "\n",
    "        neg_log_loss = -torch.sum((risk_pred - log_loss) * e) / torch.sum(e)\n",
    "        l2_loss = self.reg(model)  # 确保正则化操作也在正确的设备上执行\n",
    "\n",
    "        return neg_log_loss + l2_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "384f221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, lr, lr_decay_rate):\n",
    "    ''' Adjusts learning rate according to (epoch, lr and lr_decay_rate)\n",
    "\n",
    "    :param optimizer: (torch.optim object) 优化器\n",
    "    :param epoch: (int) 迭代次数\n",
    "    :param lr: (float) the initial learning rate 学习率\n",
    "    :param lr_decay_rate: (float) learning rate decay rate 学习率衰减率\n",
    "    :return lr_: (float) updated learning rate 返回一个更新好的学习率\n",
    "    '''\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr / (1 + epoch * lr_decay_rate)\n",
    "    return optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f610d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, test_loader, device):\n",
    "    # training\n",
    "    best_c_index = 0  # 定义一个变量 best_c_index，用于记录训练过程中最优的 c-index\n",
    "    flag = 0  # 定义一个变量 flag，用于记录训练过程中最优的 c-index 持续多少个 epoch 未更新，以便进行早停策略\n",
    "    for epoch in range(1, 501):\n",
    "        # adjusts learning rate\n",
    "        lr = adjust_learning_rate(optimizer, epoch, 0.047, 4.169e-3)\n",
    "        # train step\n",
    "        model.train()  # 模型调整到训练模式\n",
    "        for X, y, e in train_loader:  # 整个过程重复，直到处理完train_loader中所有数据\n",
    "            # 将数据移动到指定设备\n",
    "            X, y, e = X.to(device), y.to(device), e.to(device)\n",
    "            # makes predictions 做预测\n",
    "            risk_pred = model(X)  # 风险预测值\n",
    "            train_loss = criterion(risk_pred, y, e, model)  # 训练损失函数\n",
    "            train_c = c_index(-risk_pred, y, e)  # 训练出来的c指数\n",
    "            # updates parameters 更新参数\n",
    "            optimizer.zero_grad()  # 清空当前的梯度\n",
    "            train_loss.backward()  # 计算损失函数的梯度\n",
    "            optimizer.step()  # 更新模型\n",
    "        \n",
    "        # valid step\n",
    "        model.eval()  # 模型调整到测试模式\n",
    "        for X, y, e in test_loader:\n",
    "            # 将数据移动到指定设备\n",
    "            X, y, e = X.to(device), y.to(device), e.to(device)\n",
    "            # makes predictions 做预测\n",
    "            with torch.no_grad():  # 因为测试模式下，无需计算梯度，因此关闭梯度计算，以提高计算速度\n",
    "                risk_pred = model(X)  # 风险预测\n",
    "                valid_loss = criterion(risk_pred, y, e, model)  # 计算损失函数\n",
    "                valid_c = c_index(-risk_pred, y, e)  # 测试的c指数\n",
    "                if best_c_index < valid_c:\n",
    "                    best_c_index = valid_c\n",
    "                    flag = 0  # 如果当前c指数>最大c指数，更新c指数，flag=0\n",
    "                    # saves the best model 保存预测效果最好的那一次迭代\n",
    "                    torch.save({  # 并且将当前的模型保存下来\n",
    "                        'model': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'epoch': epoch}, 'test.pth')\n",
    "                else:\n",
    "                    flag += 1\n",
    "                    if flag >= 50:\n",
    "                        print(f\"Early stopping at epoch {epoch}, best c-index: {best_c_index}\")\n",
    "                        return best_c_index\n",
    "        # notes that, train loader and valid loader both have one batch!!!注意，train loader和valid loader都有一个批次!!\n",
    "        print('\\rEpoch: {}\\tLoss: {:.8f}({:.8f})\\tc-index: {:.8f}({:.8f})\\tlr: {:g}'.format(\n",
    "            epoch, train_loss.item(), valid_loss.item(), train_c, valid_c, lr), end='', flush=False)\n",
    "        print(f\"\\nFlag: {flag}, Best c-index: {best_c_index}\")\n",
    "    return best_c_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82694ef6",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "729f3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=14, out_features=32, bias=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "    (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.25, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.25, inplace=False)\n",
       "    (12): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepNN()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b46cbce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NegativeLogLikelihood().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32adaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer= optim.Adam(model.parameters(), lr= 0.047)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "facbfc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tLoss: 0.14533335(0.03169251)\tc-index: 0.51327158(0.52240192)\tlr: 0.0468049\n",
      "Flag: 0, Best c-index: 0.5224019231274774\n",
      "Epoch: 2\tLoss: 0.13854755(0.03476819)\tc-index: 0.49940124(0.50117421)\tlr: 0.0466114\n",
      "Flag: 1, Best c-index: 0.5224019231274774\n",
      "Epoch: 3\tLoss: 0.04813283(0.03635558)\tc-index: 0.51582288(0.50008763)\tlr: 0.0464194\n",
      "Flag: 2, Best c-index: 0.5224019231274774\n",
      "Epoch: 4\tLoss: 0.03951707(0.03416699)\tc-index: 0.52283723(0.51328722)\tlr: 0.0462291\n",
      "Flag: 3, Best c-index: 0.5224019231274774\n",
      "Epoch: 5\tLoss: 0.03193799(0.03379763)\tc-index: 0.53582636(0.51964970)\tlr: 0.0460403\n",
      "Flag: 4, Best c-index: 0.5224019231274774\n",
      "Epoch: 6\tLoss: 0.01644735(0.03631753)\tc-index: 0.55441530(0.51872596)\tlr: 0.045853\n",
      "Flag: 5, Best c-index: 0.5224019231274774\n",
      "Epoch: 7\tLoss: 0.00224332(0.03720739)\tc-index: 0.57249007(0.51803516)\tlr: 0.0456673\n",
      "Flag: 6, Best c-index: 0.5224019231274774\n",
      "Epoch: 8\tLoss: -0.00243901(0.03470489)\tc-index: 0.57909415(0.54667834)\tlr: 0.045483\n",
      "Flag: 0, Best c-index: 0.5466783405723232\n",
      "Epoch: 9\tLoss: -0.00674444(0.03145035)\tc-index: 0.57946367(0.56181012)\tlr: 0.0453003\n",
      "Flag: 0, Best c-index: 0.5618101174498115\n",
      "Epoch: 10\tLoss: -0.01227278(0.02771191)\tc-index: 0.58444977(0.57252329)\tlr: 0.045119\n",
      "Flag: 0, Best c-index: 0.5725232869590109\n",
      "Epoch: 11\tLoss: -0.01427916(0.02418302)\tc-index: 0.58553326(0.57820592)\tlr: 0.0449391\n",
      "Flag: 0, Best c-index: 0.5782059183488677\n",
      "Epoch: 12\tLoss: -0.01523783(0.02506761)\tc-index: 0.58857869(0.57571000)\tlr: 0.0447607\n",
      "Flag: 1, Best c-index: 0.5782059183488677\n",
      "Epoch: 13\tLoss: -0.01528281(0.02751608)\tc-index: 0.59225821(0.57288694)\tlr: 0.0445837\n",
      "Flag: 2, Best c-index: 0.5782059183488677\n",
      "Epoch: 14\tLoss: -0.01977670(0.03010216)\tc-index: 0.59396355(0.57039686)\tlr: 0.0444081\n",
      "Flag: 3, Best c-index: 0.5782059183488677\n",
      "Epoch: 15\tLoss: -0.01982315(0.03291560)\tc-index: 0.59487167(0.56691806)\tlr: 0.0442338\n",
      "Flag: 4, Best c-index: 0.5782059183488677\n",
      "Epoch: 16\tLoss: -0.02373389(0.03520711)\tc-index: 0.59594246(0.56325816)\tlr: 0.044061\n",
      "Flag: 5, Best c-index: 0.5782059183488677\n",
      "Epoch: 17\tLoss: -0.02035542(0.03648974)\tc-index: 0.59554484(0.56148882)\tlr: 0.0438894\n",
      "Flag: 6, Best c-index: 0.5782059183488677\n",
      "Epoch: 18\tLoss: -0.02263988(0.03682850)\tc-index: 0.59537575(0.56130407)\tlr: 0.0437192\n",
      "Flag: 7, Best c-index: 0.5782059183488677\n",
      "Epoch: 19\tLoss: -0.02728141(0.03614546)\tc-index: 0.60110022(0.56395151)\tlr: 0.0435503\n",
      "Flag: 8, Best c-index: 0.5782059183488677\n",
      "Epoch: 20\tLoss: -0.02768842(0.03508120)\tc-index: 0.59942989(0.56816821)\tlr: 0.0433827\n",
      "Flag: 9, Best c-index: 0.5782059183488677\n",
      "Epoch: 21\tLoss: -0.02637737(0.03375190)\tc-index: 0.59915133(0.57238819)\tlr: 0.0432164\n",
      "Flag: 10, Best c-index: 0.5782059183488677\n",
      "Epoch: 22\tLoss: -0.02627207(0.03240936)\tc-index: 0.59835018(0.57483081)\tlr: 0.0430514\n",
      "Flag: 11, Best c-index: 0.5782059183488677\n",
      "Epoch: 23\tLoss: -0.02548581(0.03061285)\tc-index: 0.59861340(0.57632996)\tlr: 0.0428876\n",
      "Flag: 12, Best c-index: 0.5782059183488677\n",
      "Epoch: 24\tLoss: -0.02915705(0.02853277)\tc-index: 0.60174053(0.57748117)\tlr: 0.0427251\n",
      "Flag: 13, Best c-index: 0.5782059183488677\n",
      "Epoch: 25\tLoss: -0.02893956(0.02463400)\tc-index: 0.60076919(0.58078654)\tlr: 0.0425638\n",
      "Flag: 0, Best c-index: 0.5807865427811157\n",
      "Epoch: 26\tLoss: -0.03387658(0.02112854)\tc-index: 0.60562993(0.58211848)\tlr: 0.0424037\n",
      "Flag: 0, Best c-index: 0.5821184779719534\n",
      "Epoch: 27\tLoss: -0.03034981(0.01612029)\tc-index: 0.60179872(0.58472649)\tlr: 0.0422448\n",
      "Flag: 0, Best c-index: 0.5847264859401973\n",
      "Epoch: 28\tLoss: -0.03379688(0.01124715)\tc-index: 0.60490553(0.58759957)\tlr: 0.0420871\n",
      "Flag: 0, Best c-index: 0.5875995665368808\n",
      "Epoch: 29\tLoss: -0.03014130(0.00633436)\tc-index: 0.60197676(0.59045987)\tlr: 0.0419306\n",
      "Flag: 0, Best c-index: 0.5904598681500998\n",
      "Epoch: 30\tLoss: -0.03507482(0.00112271)\tc-index: 0.60611459(0.59324240)\tlr: 0.0417752\n",
      "Flag: 0, Best c-index: 0.5932424005210905\n",
      "Epoch: 31\tLoss: -0.03337835(-0.00276218)\tc-index: 0.60429368(0.59477478)\tlr: 0.041621\n",
      "Flag: 0, Best c-index: 0.5947747831954177\n",
      "Epoch: 32\tLoss: -0.03115654(-0.00646244)\tc-index: 0.60267914(0.59625386)\tlr: 0.0414679\n",
      "Flag: 0, Best c-index: 0.5962538592530063\n",
      "Epoch: 33\tLoss: -0.03465550(-0.00933549)\tc-index: 0.60579100(0.59738097)\tlr: 0.0413159\n",
      "Flag: 0, Best c-index: 0.5973809655945952\n",
      "Epoch: 34\tLoss: -0.03466950(-0.01156511)\tc-index: 0.60514163(0.59871947)\tlr: 0.041165\n",
      "Flag: 0, Best c-index: 0.5987194728340718\n",
      "Epoch: 35\tLoss: -0.03422800(-0.01357756)\tc-index: 0.60455710(0.60031283)\tlr: 0.0410153\n",
      "Flag: 0, Best c-index: 0.6003128295152165\n",
      "Epoch: 36\tLoss: -0.03853951(-0.01504507)\tc-index: 0.60806130(0.60147827)\tlr: 0.0408666\n",
      "Flag: 0, Best c-index: 0.6014782728071995\n",
      "Epoch: 37\tLoss: -0.03853407(-0.01634390)\tc-index: 0.60879070(0.60269410)\tlr: 0.040719\n",
      "Flag: 0, Best c-index: 0.6026941018054148\n",
      "Epoch: 38\tLoss: -0.04345893(-0.01778878)\tc-index: 0.61148538(0.60398222)\tlr: 0.0405724\n",
      "Flag: 0, Best c-index: 0.6039822233386591\n",
      "Epoch: 39\tLoss: -0.03722315(-0.01881637)\tc-index: 0.60793793(0.60504616)\tlr: 0.0404269\n",
      "Flag: 0, Best c-index: 0.6050461649905509\n",
      "Epoch: 40\tLoss: -0.04525530(-0.02028486)\tc-index: 0.61274291(0.60609404)\tlr: 0.0402825\n",
      "Flag: 0, Best c-index: 0.6060940416346584\n",
      "Epoch: 41\tLoss: -0.04313753(-0.02124829)\tc-index: 0.61336815(0.60689510)\tlr: 0.0401391\n",
      "Flag: 0, Best c-index: 0.60689510134099\n",
      "Epoch: 42\tLoss: -0.04051683(-0.02238683)\tc-index: 0.61013839(0.60805981)\tlr: 0.0399967\n",
      "Flag: 0, Best c-index: 0.6080598144053464\n",
      "Epoch: 43\tLoss: -0.04190382(-0.02287442)\tc-index: 0.61102307(0.60856732)\tlr: 0.0398553\n",
      "Flag: 0, Best c-index: 0.6085673226058027\n",
      "Epoch: 44\tLoss: -0.04341606(-0.02306760)\tc-index: 0.61011583(0.60925885)\tlr: 0.0397149\n",
      "Flag: 0, Best c-index: 0.609258848168151\n",
      "Epoch: 45\tLoss: -0.04143503(-0.02279214)\tc-index: 0.61046162(0.60936546)\tlr: 0.0395754\n",
      "Flag: 0, Best c-index: 0.6093654614016281\n",
      "Epoch: 46\tLoss: -0.04110625(-0.02291596)\tc-index: 0.61017309(0.60976271)\tlr: 0.039437\n",
      "Flag: 0, Best c-index: 0.6097627052304745\n",
      "Epoch: 47\tLoss: -0.04392631(-0.02384545)\tc-index: 0.61296194(0.60986822)\tlr: 0.0392995\n",
      "Flag: 0, Best c-index: 0.6098682231225118\n",
      "Epoch: 48\tLoss: -0.04513511(-0.02533715)\tc-index: 0.61347228(0.60990510)\tlr: 0.039163\n",
      "Flag: 0, Best c-index: 0.6099050996176528\n",
      "Epoch: 49\tLoss: -0.04916456(-0.02670177)\tc-index: 0.61638966(0.60980506)\tlr: 0.0390274\n",
      "Flag: 1, Best c-index: 0.6099050996176528\n",
      "Epoch: 50\tLoss: -0.04605678(-0.02811512)\tc-index: 0.61465705(0.60987954)\tlr: 0.0388928\n",
      "Flag: 2, Best c-index: 0.6099050996176528\n",
      "Epoch: 51\tLoss: -0.04834218(-0.02965217)\tc-index: 0.61579129(0.61009788)\tlr: 0.0387591\n",
      "Flag: 0, Best c-index: 0.6100978797110636\n",
      "Epoch: 52\tLoss: -0.04482456(-0.03056799)\tc-index: 0.61405091(0.60978315)\tlr: 0.0386263\n",
      "Flag: 1, Best c-index: 0.6100978797110636\n",
      "Epoch: 53\tLoss: -0.04635597(-0.03074518)\tc-index: 0.61511686(0.60969260)\tlr: 0.0384944\n",
      "Flag: 2, Best c-index: 0.6100978797110636\n",
      "Epoch: 54\tLoss: -0.04796620(-0.03135226)\tc-index: 0.61490211(0.60974737)\tlr: 0.0383634\n",
      "Flag: 3, Best c-index: 0.6100978797110636\n",
      "Epoch: 55\tLoss: -0.04907415(-0.03219588)\tc-index: 0.61614029(0.61022275)\tlr: 0.0382333\n",
      "Flag: 0, Best c-index: 0.6102227486352045\n",
      "Epoch: 56\tLoss: -0.05600271(-0.03412930)\tc-index: 0.61967618(0.61095225)\tlr: 0.0381041\n",
      "Flag: 0, Best c-index: 0.6109522460341338\n",
      "Epoch: 57\tLoss: -0.04818999(-0.03593233)\tc-index: 0.61593853(0.61115744)\tlr: 0.0379757\n",
      "Flag: 0, Best c-index: 0.611157439997196\n",
      "Epoch: 58\tLoss: -0.04745526(-0.03773862)\tc-index: 0.61591344(0.61108807)\tlr: 0.0378482\n",
      "Flag: 1, Best c-index: 0.611157439997196\n",
      "Epoch: 59\tLoss: -0.05461358(-0.03960296)\tc-index: 0.61807886(0.61091573)\tlr: 0.0377216\n",
      "Flag: 2, Best c-index: 0.611157439997196\n",
      "Epoch: 60\tLoss: -0.05139454(-0.04072608)\tc-index: 0.61791381(0.61042283)\tlr: 0.0375958\n",
      "Flag: 3, Best c-index: 0.611157439997196\n",
      "Epoch: 61\tLoss: -0.05778247(-0.04071578)\tc-index: 0.61886494(0.60993066)\tlr: 0.0374708\n",
      "Flag: 4, Best c-index: 0.611157439997196\n",
      "Epoch: 62\tLoss: -0.05001761(-0.04103864)\tc-index: 0.61549815(0.60945382)\tlr: 0.0373467\n",
      "Flag: 5, Best c-index: 0.611157439997196\n",
      "Epoch: 63\tLoss: -0.05335997(-0.04130645)\tc-index: 0.61762594(0.60903686)\tlr: 0.0372234\n",
      "Flag: 6, Best c-index: 0.611157439997196\n",
      "Epoch: 64\tLoss: -0.05507157(-0.04199335)\tc-index: 0.61891958(0.60916209)\tlr: 0.0371009\n",
      "Flag: 7, Best c-index: 0.611157439997196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65\tLoss: -0.05480414(-0.04240985)\tc-index: 0.61951628(0.60919459)\tlr: 0.0369792\n",
      "Flag: 8, Best c-index: 0.611157439997196\n",
      "Epoch: 66\tLoss: -0.05618580(-0.04305890)\tc-index: 0.61846217(0.60861260)\tlr: 0.0368583\n",
      "Flag: 9, Best c-index: 0.611157439997196\n",
      "Epoch: 67\tLoss: -0.05916560(-0.04392220)\tc-index: 0.62111702(0.60815766)\tlr: 0.0367382\n",
      "Flag: 10, Best c-index: 0.611157439997196\n",
      "Epoch: 68\tLoss: -0.06025360(-0.04508323)\tc-index: 0.62220356(0.60846363)\tlr: 0.0366188\n",
      "Flag: 11, Best c-index: 0.611157439997196\n",
      "Epoch: 69\tLoss: -0.05945902(-0.04586243)\tc-index: 0.62046407(0.60862647)\tlr: 0.0365003\n",
      "Flag: 12, Best c-index: 0.611157439997196\n",
      "Epoch: 70\tLoss: -0.05699246(-0.04549984)\tc-index: 0.62144637(0.60849065)\tlr: 0.0363825\n",
      "Flag: 13, Best c-index: 0.611157439997196\n",
      "Epoch: 71\tLoss: -0.05735227(-0.04415003)\tc-index: 0.62132970(0.60829714)\tlr: 0.0362655\n",
      "Flag: 14, Best c-index: 0.611157439997196\n",
      "Epoch: 72\tLoss: -0.05977945(-0.04357304)\tc-index: 0.62110461(0.60861844)\tlr: 0.0361492\n",
      "Flag: 15, Best c-index: 0.611157439997196\n",
      "Epoch: 73\tLoss: -0.05977108(-0.04291055)\tc-index: 0.62227643(0.60892879)\tlr: 0.0360336\n",
      "Flag: 16, Best c-index: 0.611157439997196\n",
      "Epoch: 74\tLoss: -0.06429685(-0.04242765)\tc-index: 0.62625882(0.60968749)\tlr: 0.0359188\n",
      "Flag: 17, Best c-index: 0.611157439997196\n",
      "Epoch: 75\tLoss: -0.05979124(-0.04255255)\tc-index: 0.62326886(0.61051192)\tlr: 0.0358047\n",
      "Flag: 18, Best c-index: 0.611157439997196\n",
      "Epoch: 76\tLoss: -0.06031412(-0.04290613)\tc-index: 0.62346058(0.61164085)\tlr: 0.0356914\n",
      "Flag: 0, Best c-index: 0.6116408506859758\n",
      "Epoch: 77\tLoss: -0.06495293(-0.04399048)\tc-index: 0.62560424(0.61257919)\tlr: 0.0355788\n",
      "Flag: 0, Best c-index: 0.6125791931861\n",
      "Epoch: 78\tLoss: -0.06184685(-0.04368957)\tc-index: 0.62417721(0.61274495)\tlr: 0.0354668\n",
      "Flag: 0, Best c-index: 0.6127449548573282\n",
      "Epoch: 79\tLoss: -0.06397080(-0.04294164)\tc-index: 0.62475684(0.61266317)\tlr: 0.0353556\n",
      "Flag: 1, Best c-index: 0.6127449548573282\n",
      "Epoch: 80\tLoss: -0.06489083(-0.04282453)\tc-index: 0.62682119(0.61227177)\tlr: 0.0352451\n",
      "Flag: 2, Best c-index: 0.6127449548573282\n",
      "Epoch: 81\tLoss: -0.06634158(-0.04176598)\tc-index: 0.62403912(0.61125018)\tlr: 0.0351352\n",
      "Flag: 3, Best c-index: 0.6127449548573282\n",
      "Epoch: 82\tLoss: -0.06370138(-0.04164028)\tc-index: 0.62091204(0.61084344)\tlr: 0.0350261\n",
      "Flag: 4, Best c-index: 0.6127449548573282\n",
      "Epoch: 83\tLoss: -0.06706893(-0.04247174)\tc-index: 0.62428734(0.61108369)\tlr: 0.0349176\n",
      "Flag: 5, Best c-index: 0.6127449548573282\n",
      "Epoch: 84\tLoss: -0.06371893(-0.04266810)\tc-index: 0.62564050(0.61139695)\tlr: 0.0348098\n",
      "Flag: 6, Best c-index: 0.6127449548573282\n",
      "Epoch: 85\tLoss: -0.06677537(-0.04254935)\tc-index: 0.62433107(0.61243972)\tlr: 0.0347026\n",
      "Flag: 7, Best c-index: 0.6127449548573282\n",
      "Epoch: 86\tLoss: -0.06453446(-0.04300762)\tc-index: 0.62326998(0.61351827)\tlr: 0.0345961\n",
      "Flag: 0, Best c-index: 0.6135182659138506\n",
      "Epoch: 87\tLoss: -0.07177193(-0.04323623)\tc-index: 0.62743492(0.61420833)\tlr: 0.0344903\n",
      "Flag: 0, Best c-index: 0.6142083310209459\n",
      "Epoch: 88\tLoss: -0.07225527(-0.04452074)\tc-index: 0.62767033(0.61525475)\tlr: 0.0343851\n",
      "Flag: 0, Best c-index: 0.6152547472098002\n",
      "Epoch: 89\tLoss: -0.06893104(-0.04584745)\tc-index: 0.62537764(0.61573597)\tlr: 0.0342805\n",
      "Flag: 0, Best c-index: 0.6157359672157005\n",
      "Epoch: 90\tLoss: -0.06832060(-0.04496901)\tc-index: 0.62746542(0.61580169)\tlr: 0.0341766\n",
      "Flag: 0, Best c-index: 0.6158016877020905\n",
      "Epoch: 91\tLoss: -0.07150911(-0.04558483)\tc-index: 0.62932093(0.61604485)\tlr: 0.0340733\n",
      "Flag: 0, Best c-index: 0.6160448535017335\n",
      "Epoch: 92\tLoss: -0.07622591(-0.04701738)\tc-index: 0.63057505(0.61606822)\tlr: 0.0339706\n",
      "Flag: 0, Best c-index: 0.6160682207857834\n",
      "Epoch: 93\tLoss: -0.07042214(-0.04762565)\tc-index: 0.62700312(0.61409222)\tlr: 0.0338686\n",
      "Flag: 1, Best c-index: 0.6160682207857834\n",
      "Epoch: 94\tLoss: -0.06713046(-0.04728188)\tc-index: 0.62751658(0.61283842)\tlr: 0.0337671\n",
      "Flag: 2, Best c-index: 0.6160682207857834\n",
      "Epoch: 95\tLoss: -0.06941182(-0.04639099)\tc-index: 0.62702930(0.61167298)\tlr: 0.0336663\n",
      "Flag: 3, Best c-index: 0.6160682207857834\n",
      "Epoch: 96\tLoss: -0.07362947(-0.04474832)\tc-index: 0.62921479(0.61099752)\tlr: 0.0335661\n",
      "Flag: 4, Best c-index: 0.6160682207857834\n",
      "Epoch: 97\tLoss: -0.06990743(-0.04318894)\tc-index: 0.62572499(0.61058494)\tlr: 0.0334664\n",
      "Flag: 5, Best c-index: 0.6160682207857834\n",
      "Epoch: 98\tLoss: -0.07120645(-0.04236620)\tc-index: 0.62613245(0.61085001)\tlr: 0.0333674\n",
      "Flag: 6, Best c-index: 0.6160682207857834\n",
      "Epoch: 99\tLoss: -0.06791952(-0.04235380)\tc-index: 0.62619759(0.61167371)\tlr: 0.0332689\n",
      "Flag: 7, Best c-index: 0.6160682207857834\n",
      "Epoch: 100\tLoss: -0.06790686(-0.04341204)\tc-index: 0.62490465(0.61285668)\tlr: 0.033171\n",
      "Flag: 8, Best c-index: 0.6160682207857834\n",
      "Epoch: 101\tLoss: -0.07479377(-0.04509369)\tc-index: 0.62902091(0.61413823)\tlr: 0.0330737\n",
      "Flag: 9, Best c-index: 0.6160682207857834\n",
      "Epoch: 102\tLoss: -0.07230774(-0.04599868)\tc-index: 0.62951857(0.61511308)\tlr: 0.0329769\n",
      "Flag: 10, Best c-index: 0.6160682207857834\n",
      "Epoch: 103\tLoss: -0.07442029(-0.04560942)\tc-index: 0.63004441(0.61550668)\tlr: 0.0328808\n",
      "Flag: 11, Best c-index: 0.6160682207857834\n",
      "Epoch: 104\tLoss: -0.07441606(-0.04463703)\tc-index: 0.63239956(0.61554100)\tlr: 0.0327851\n",
      "Flag: 12, Best c-index: 0.6160682207857834\n",
      "Epoch: 105\tLoss: -0.07496353(-0.04425523)\tc-index: 0.62928303(0.61590392)\tlr: 0.0326901\n",
      "Flag: 13, Best c-index: 0.6160682207857834\n",
      "Epoch: 106\tLoss: -0.07581080(-0.04404491)\tc-index: 0.62994613(0.61648445)\tlr: 0.0325956\n",
      "Flag: 0, Best c-index: 0.6164844505329201\n",
      "Epoch: 107\tLoss: -0.07024847(-0.04565368)\tc-index: 0.62747452(0.61740892)\tlr: 0.0325016\n",
      "Flag: 0, Best c-index: 0.6174089187081397\n",
      "Epoch: 108\tLoss: -0.07390815(-0.04656816)\tc-index: 0.62757987(0.61802523)\tlr: 0.0324082\n",
      "Flag: 0, Best c-index: 0.6180252308249528\n",
      "Epoch: 109\tLoss: -0.07468589(-0.04825927)\tc-index: 0.62761087(0.61889420)\tlr: 0.0323153\n",
      "Flag: 0, Best c-index: 0.6188942017005541\n",
      "Epoch: 110\tLoss: -0.07377762(-0.04940971)\tc-index: 0.62710034(0.61940974)\tlr: 0.0322229\n",
      "Flag: 0, Best c-index: 0.6194097424049024\n",
      "Epoch: 111\tLoss: -0.08198541(-0.05100447)\tc-index: 0.63275012(0.61947911)\tlr: 0.0321311\n",
      "Flag: 0, Best c-index: 0.6194791140294252\n",
      "Epoch: 112\tLoss: -0.07289490(-0.05073910)\tc-index: 0.62690651(0.61961421)\tlr: 0.0320397\n",
      "Flag: 0, Best c-index: 0.619614206140338\n",
      "Epoch: 113\tLoss: -0.08055499(-0.04884075)\tc-index: 0.63213634(0.61892268)\tlr: 0.0319489\n",
      "Flag: 1, Best c-index: 0.619614206140338\n",
      "Epoch: 114\tLoss: -0.08306881(-0.04705692)\tc-index: 0.63360013(0.61736072)\tlr: 0.0318587\n",
      "Flag: 2, Best c-index: 0.619614206140338\n",
      "Epoch: 115\tLoss: -0.07908685(-0.04537995)\tc-index: 0.63241825(0.61517369)\tlr: 0.0317689\n",
      "Flag: 3, Best c-index: 0.619614206140338\n",
      "Epoch: 116\tLoss: -0.08329084(-0.04693890)\tc-index: 0.63372621(0.61412801)\tlr: 0.0316796\n",
      "Flag: 4, Best c-index: 0.619614206140338\n",
      "Epoch: 117\tLoss: -0.07982739(-0.04789077)\tc-index: 0.63084701(0.61303559)\tlr: 0.0315908\n",
      "Flag: 5, Best c-index: 0.619614206140338\n",
      "Epoch: 118\tLoss: -0.08212634(-0.04888533)\tc-index: 0.63432093(0.61253684)\tlr: 0.0315026\n",
      "Flag: 6, Best c-index: 0.619614206140338\n",
      "Epoch: 119\tLoss: -0.07927866(-0.04874243)\tc-index: 0.62996771(0.61068279)\tlr: 0.0314148\n",
      "Flag: 7, Best c-index: 0.619614206140338\n",
      "Epoch: 120\tLoss: -0.08419253(-0.04874113)\tc-index: 0.63207200(0.60968822)\tlr: 0.0313275\n",
      "Flag: 8, Best c-index: 0.619614206140338\n",
      "Epoch: 121\tLoss: -0.08054528(-0.04885627)\tc-index: 0.63061013(0.61011029)\tlr: 0.0312407\n",
      "Flag: 9, Best c-index: 0.619614206140338\n",
      "Epoch: 122\tLoss: -0.08646176(-0.04749092)\tc-index: 0.63402779(0.61015557)\tlr: 0.0311543\n",
      "Flag: 10, Best c-index: 0.619614206140338\n",
      "Epoch: 123\tLoss: -0.08715791(-0.04557857)\tc-index: 0.63368683(0.60997666)\tlr: 0.0310685\n",
      "Flag: 11, Best c-index: 0.619614206140338\n",
      "Epoch: 124\tLoss: -0.08700012(-0.04472899)\tc-index: 0.63638147(0.60950567)\tlr: 0.0309831\n",
      "Flag: 12, Best c-index: 0.619614206140338\n",
      "Epoch: 125\tLoss: -0.09070440(-0.04440515)\tc-index: 0.63689575(0.60838842)\tlr: 0.0308982\n",
      "Flag: 13, Best c-index: 0.619614206140338\n",
      "Epoch: 126\tLoss: -0.09419055(-0.04600031)\tc-index: 0.63790834(0.60941220)\tlr: 0.0308137\n",
      "Flag: 14, Best c-index: 0.619614206140338\n",
      "Epoch: 127\tLoss: -0.09100288(-0.04908023)\tc-index: 0.63530800(0.61185335)\tlr: 0.0307297\n",
      "Flag: 15, Best c-index: 0.619614206140338\n",
      "Epoch: 128\tLoss: -0.08534707(-0.05041676)\tc-index: 0.63588046(0.61373186)\tlr: 0.0306462\n",
      "Flag: 16, Best c-index: 0.619614206140338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 129\tLoss: -0.08970614(-0.04939338)\tc-index: 0.63544333(0.61357449)\tlr: 0.0305631\n",
      "Flag: 17, Best c-index: 0.619614206140338\n",
      "Epoch: 130\tLoss: -0.08364449(-0.04795608)\tc-index: 0.63469541(0.61298703)\tlr: 0.0304805\n",
      "Flag: 18, Best c-index: 0.619614206140338\n",
      "Epoch: 131\tLoss: -0.09188589(-0.04617238)\tc-index: 0.63771653(0.61185846)\tlr: 0.0303983\n",
      "Flag: 19, Best c-index: 0.619614206140338\n",
      "Epoch: 132\tLoss: -0.09070016(-0.04607172)\tc-index: 0.63698486(0.61295745)\tlr: 0.0303166\n",
      "Flag: 20, Best c-index: 0.619614206140338\n",
      "Epoch: 133\tLoss: -0.08941592(-0.04720452)\tc-index: 0.63475375(0.61515763)\tlr: 0.0302352\n",
      "Flag: 21, Best c-index: 0.619614206140338\n",
      "Epoch: 134\tLoss: -0.08813816(-0.04775147)\tc-index: 0.63653189(0.61465596)\tlr: 0.0301544\n",
      "Flag: 22, Best c-index: 0.619614206140338\n",
      "Epoch: 135\tLoss: -0.08966997(-0.04463486)\tc-index: 0.63643719(0.61198844)\tlr: 0.0300739\n",
      "Flag: 23, Best c-index: 0.619614206140338\n",
      "Epoch: 136\tLoss: -0.09004361(-0.03903951)\tc-index: 0.63316544(0.60876667)\tlr: 0.0299939\n",
      "Flag: 24, Best c-index: 0.619614206140338\n",
      "Epoch: 137\tLoss: -0.09236029(-0.03654120)\tc-index: 0.63729614(0.60790720)\tlr: 0.0299143\n",
      "Flag: 25, Best c-index: 0.619614206140338\n",
      "Epoch: 138\tLoss: -0.08950271(-0.03433413)\tc-index: 0.63754572(0.60555148)\tlr: 0.0298352\n",
      "Flag: 26, Best c-index: 0.619614206140338\n",
      "Epoch: 139\tLoss: -0.09139256(-0.03460118)\tc-index: 0.63646675(0.60503631)\tlr: 0.0297564\n",
      "Flag: 27, Best c-index: 0.619614206140338\n",
      "Epoch: 140\tLoss: -0.08869066(-0.03695950)\tc-index: 0.63429009(0.60532110)\tlr: 0.0296781\n",
      "Flag: 28, Best c-index: 0.619614206140338\n",
      "Epoch: 141\tLoss: -0.08445273(-0.04087057)\tc-index: 0.63487725(0.60753040)\tlr: 0.0296002\n",
      "Flag: 29, Best c-index: 0.619614206140338\n",
      "Epoch: 142\tLoss: -0.09334172(-0.03975075)\tc-index: 0.63978676(0.60686188)\tlr: 0.0295227\n",
      "Flag: 30, Best c-index: 0.619614206140338\n",
      "Epoch: 143\tLoss: -0.08687597(-0.03810563)\tc-index: 0.63521951(0.60611412)\tlr: 0.0294455\n",
      "Flag: 31, Best c-index: 0.619614206140338\n",
      "Epoch: 144\tLoss: -0.09239104(-0.03845780)\tc-index: 0.63861309(0.60688743)\tlr: 0.0293688\n",
      "Flag: 32, Best c-index: 0.619614206140338\n",
      "Epoch: 145\tLoss: -0.08714044(-0.04114234)\tc-index: 0.63616147(0.60942242)\tlr: 0.0292925\n",
      "Flag: 33, Best c-index: 0.619614206140338\n",
      "Epoch: 146\tLoss: -0.08951695(-0.04224549)\tc-index: 0.63606881(0.61150101)\tlr: 0.0292166\n",
      "Flag: 34, Best c-index: 0.619614206140338\n",
      "Epoch: 147\tLoss: -0.09138413(-0.04375909)\tc-index: 0.63468943(0.61346569)\tlr: 0.0291411\n",
      "Flag: 35, Best c-index: 0.619614206140338\n",
      "Epoch: 148\tLoss: -0.08814126(-0.03960886)\tc-index: 0.63476212(0.61217757)\tlr: 0.029066\n",
      "Flag: 36, Best c-index: 0.619614206140338\n",
      "Epoch: 149\tLoss: -0.09388333(-0.03308691)\tc-index: 0.63936929(0.60984595)\tlr: 0.0289912\n",
      "Flag: 37, Best c-index: 0.619614206140338\n",
      "Epoch: 150\tLoss: -0.09155945(-0.02935241)\tc-index: 0.63874627(0.60726423)\tlr: 0.0289168\n",
      "Flag: 38, Best c-index: 0.619614206140338\n",
      "Epoch: 151\tLoss: -0.09151235(-0.03308244)\tc-index: 0.63933762(0.60712512)\tlr: 0.0288429\n",
      "Flag: 39, Best c-index: 0.619614206140338\n",
      "Epoch: 152\tLoss: -0.09038605(-0.03281262)\tc-index: 0.63800742(0.60449010)\tlr: 0.0287693\n",
      "Flag: 40, Best c-index: 0.619614206140338\n",
      "Epoch: 153\tLoss: -0.08739217(-0.03289019)\tc-index: 0.63654340(0.60221033)\tlr: 0.028696\n",
      "Flag: 41, Best c-index: 0.619614206140338\n",
      "Epoch: 154\tLoss: -0.09628183(-0.03326766)\tc-index: 0.64001634(0.60166996)\tlr: 0.0286232\n",
      "Flag: 42, Best c-index: 0.619614206140338\n",
      "Epoch: 155\tLoss: -0.09532505(-0.03381666)\tc-index: 0.64141492(0.60253090)\tlr: 0.0285507\n",
      "Flag: 43, Best c-index: 0.619614206140338\n",
      "Epoch: 156\tLoss: -0.08693396(-0.03566402)\tc-index: 0.63652455(0.60392344)\tlr: 0.0284786\n",
      "Flag: 44, Best c-index: 0.619614206140338\n",
      "Epoch: 157\tLoss: -0.09419107(-0.03776657)\tc-index: 0.64021754(0.60522032)\tlr: 0.0284068\n",
      "Flag: 45, Best c-index: 0.619614206140338\n",
      "Epoch: 158\tLoss: -0.09669062(-0.04042661)\tc-index: 0.64215491(0.60622621)\tlr: 0.0283354\n",
      "Flag: 46, Best c-index: 0.619614206140338\n",
      "Epoch: 159\tLoss: -0.09310058(-0.04184668)\tc-index: 0.63895675(0.60564495)\tlr: 0.0282644\n",
      "Flag: 47, Best c-index: 0.619614206140338\n",
      "Epoch: 160\tLoss: -0.10295882(-0.04103205)\tc-index: 0.64247477(0.60338125)\tlr: 0.0281937\n",
      "Flag: 48, Best c-index: 0.619614206140338\n",
      "Epoch: 161\tLoss: -0.09315238(-0.03907550)\tc-index: 0.63970167(0.60185580)\tlr: 0.0281234\n",
      "Flag: 49, Best c-index: 0.619614206140338\n",
      "Early stopping at epoch 162, best c-index: 0.619614206140338\n"
     ]
    }
   ],
   "source": [
    "best_c_index = train(model,criterion,optimizer,train_loader,test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d87a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.616195280392804"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_c_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
